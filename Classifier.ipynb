{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeEy/XlaX0Q65E2bQRPB55",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlangsman/fastai-experiments/blob/main/Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ¤– Classifier Experiment"
      ],
      "metadata": {
        "id": "Zp3psduXp2PN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“ Install dependencies\n",
        "\n",
        "We need the Fastai library for model training and DuckDuckGo search to retrieve images for our dataset.\n"
      ],
      "metadata": {
        "id": "dVgy6dSfqnpF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWVy_dM2pLzR",
        "outputId": "3328188e-1a08-4837-af0e-d0e6c113ba4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/41.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/5.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m208.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq fastai ddgs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download images\n",
        "\n",
        "Create a function which can download images using the DuckDuckGo API for training."
      ],
      "metadata": {
        "id": "9Vf7Oq5CsWFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ddgs import DDGS\n",
        "from fastcore.all import *\n",
        "\n",
        "def search_images(keywords, max_images=10):\n",
        "  results = DDGS().images(keywords, max_results=max_images) #run a search\n",
        "  imageUrls = L(results).itemgot('image') #extract just image urls\n",
        "  return imageUrls\n"
      ],
      "metadata": {
        "id": "-oZJT5NfsfMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifying UPF food is a little trickier than say cats/dogs. Here I create a list of search terms for specific foods and so we can then grab images for each\n"
      ],
      "metadata": {
        "id": "vfUy6AgA3VwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ultra-processed food terms (UPF)\n",
        "upf_terms = [\n",
        "    \"Big Mac burger\",\n",
        "    \"Doritos crisps\",\n",
        "    \"KitKat bar\",\n",
        "    \"Oreo cookies\",\n",
        "    \"Pringles tube\",\n",
        "    \"Pot Noodle\",\n",
        "    \"Twix bar\",\n",
        "    \"Haribo sweets\",\n",
        "    \"Coca-Cola can\",\n",
        "    \"Fanta bottle\",\n",
        "    \"Red Bull can\",\n",
        "    \"Pop-Tarts\",\n",
        "    \"Ben & Jerry's ice cream tub\",\n",
        "    \"Chicken nuggets\",\n",
        "    \"Pepperami\",\n",
        "    \"Frozen pizza\",\n",
        "    \"Pot noodle\",\n",
        "    \"Mars bar\",\n",
        "    \"Snickers bar\",\n",
        "    \"Chocolate bar\"\n",
        "    \"Walkers crisps\",\n",
        "    \"Crisps\"\n",
        "]\n",
        "\n",
        "# Fresh / minimally-processed foods\n",
        "fresh_terms = [\n",
        "    \"Apple fruit\",\n",
        "    \"Banana fruit\",\n",
        "    \"Broccoli\",\n",
        "    \"Carrot\",\n",
        "    \"Tomato\",\n",
        "    \"Cucumber\",\n",
        "    \"Lettuce\",\n",
        "    \"Blueberries\",\n",
        "    \"Strawberries\",\n",
        "    \"Eggs\",\n",
        "    \"Whole chicken raw\",\n",
        "    \"Salmon fillet\",\n",
        "    \"Beef steak\",\n",
        "    \"Brown rice bowl\",\n",
        "    \"Oats porridge\",\n",
        "    \"Almonds nuts\",\n",
        "    \"Avocado\",\n",
        "    \"Red bell pepper\",\n",
        "    \"Courgette\",\n",
        "    \"Mushrooms\"\n",
        "]"
      ],
      "metadata": {
        "id": "37Ws0jRa28Cn"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test these work correctly by downloading some images for each term. FastAi's download_url() seems to stall on some urls so here I'm doing an http request instead to get the images."
      ],
      "metadata": {
        "id": "LwT00nFtEB5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from fastdownload import download_url\n",
        "from fastai.vision.all import *\n",
        "from io import BytesIO\n",
        "import random\n",
        "\n",
        "thumbs = []\n",
        "\n",
        "for item in upf_terms:\n",
        "  urls = search_images(item, max_images=3)\n",
        "  for i, url in enumerate(urls):\n",
        "    dest = f\"{item.replace(' ', '_')}_{i}.jpg\"\n",
        "    try:\n",
        "      r = requests.get(url, timeout=4, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "      r.raise_for_status()\n",
        "      if \"image\" not in r.headers.get(\"Content-Type\", \"\"): # skip non-image content\n",
        "        continue\n",
        "\n",
        "      # Create image from raw bytes and also write to disk\n",
        "      img = PILImage.create(BytesIO(r.content))\n",
        "      with open(dest, \"wb\") as f:\n",
        "                f.write(r.content)\n",
        "      thumbs.append(img.to_thumb(64,64))\n",
        "    except Exception as e:\n",
        "      pass\n",
        "\n",
        "show_images(thumbs, nrows=len(upf_terms))\n",
        "\n"
      ],
      "metadata": {
        "id": "qmjHJrDWt5XI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}